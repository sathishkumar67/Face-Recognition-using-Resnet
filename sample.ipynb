{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.19.0 (from -r requirements.txt (line 1))\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: mtcnn==1.0.0 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
      "Requirement already satisfied: huggingface-hub==0.30.2 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (0.30.2)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: joblib>=1.4.2 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from mtcnn==1.0.0->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: lz4>=4.3.3 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from mtcnn==1.0.0->-r requirements.txt (line 2)) (4.4.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from tqdm==4.67.1->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 6)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 6)) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (0.44.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sathish\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.8/4.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.6/4.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/3.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.8/3.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.9/3.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 4.5 MB/s eta 0:00:00\n",
      "Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, MarkupSafe, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, werkzeug, markdown-it-py, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.9 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sathishkumar67/Face-Recognition-using-Resnet.git\n",
    "!mv /kaggle/working/Face-Recognition-using-Resnet/* /kaggle/working/\n",
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from siamese_resnet import unzip_file\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87696724",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_REPO_ID = \"pt-sk/Face_Recognition_Dataset\"\n",
    "DATASET_FILENAME_IN_REPO = \"Face Recognition Dataset.zip\"\n",
    "DATASET_REPO_TYPE = \"dataset\"\n",
    "LOCAL_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fe865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from Hugging Face Hub\n",
    "hf_hub_download(repo_id=DATASET_REPO_ID, filename=DATASET_FILENAME_IN_REPO, repo_type=DATASET_REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "\n",
    "# Unzip the dataset\n",
    "unzip_file(os.path.join(LOCAL_DIR, DATASET_FILENAME_IN_REPO), LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet loss function\n",
    "# This function computes the triplet loss for a batch of anchor, positive, and negative samples.\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        # Compute pairwise distances\n",
    "        distance_positive = F.pairwise_distance(anchor, positive)\n",
    "        distance_negative = F.pairwise_distance(anchor, negative)\n",
    "        \n",
    "        # Calculate triplet loss\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseResNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=256):\n",
    "        super(SiameseResNet, self).__init__()\n",
    "        # Load pretrained ResNet18\n",
    "        self.backbone = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        self.backbone.fc = nn.Linear(512, embedding_dim)  # 512 -> 256\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def print_parameters_count(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters()) / 1e6  # Convert to millions\n",
    "        # Print the number of parameters in millions\n",
    "        print(f\"Total parameters: {total_params:.2f}m\")\n",
    "    \n",
    "model = SiameseResNet(embedding_dim=256)\n",
    "# model.print_parameters_count()\n",
    "\n",
    "# pass a sample image through the model\n",
    "dummy_input = torch.randn(1, 3, 224, 224)  # batch size of 1, 3 channels, 224x224 image\n",
    "output = model(dummy_input)\n",
    "# output.shape  # should be (1, 256) since we changed the final layer to output 256 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.id_to_images = defaultdict(list)\n",
    "        \n",
    "        # Populate identities and their images\n",
    "        for identity in os.listdir(root_dir):\n",
    "            identity_dir = os.path.join(root_dir, identity)\n",
    "            if os.path.isdir(identity_dir):\n",
    "                images = [os.path.join(identity_dir, img) \n",
    "                        for img in os.listdir(identity_dir) \n",
    "                        if img.endswith(('.jpg', '.png'))]\n",
    "                if len(images) >= 2:  # Ensure at least 2 images per identity\n",
    "                    self.id_to_images[identity] = images\n",
    "        self.identities = list(self.id_to_images.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.identities) * 10  # Adjust based on your needs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Anchor and positive from the same identity\n",
    "        anchor_id = self.identities[idx % len(self.identities)]\n",
    "        anchor_img_path, positive_img_path = random.sample(self.id_to_images[anchor_id], 2)\n",
    "        \n",
    "        # Negative from a different identity\n",
    "        negative_id = random.choice(self.identities)\n",
    "        while negative_id == anchor_id:\n",
    "            negative_id = random.choice(self.identities)\n",
    "        negative_img_path = random.choice(self.id_to_images[negative_id])\n",
    "        \n",
    "        # Load and transform images\n",
    "        anchor = Image.open(anchor_img_path).convert('RGB')\n",
    "        positive = Image.open(positive_img_path).convert('RGB')\n",
    "        negative = Image.open(negative_img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "        \n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a757a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletFaceDataset(root_dir='sample_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a01bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================== Usage Example ======================\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = TripletDatasetGenerator(DATA_ROOT)\n",
    "    \n",
    "    # Create splits\n",
    "    splits = generator.create_splits()\n",
    "    \n",
    "    # Generate triplets for each split\n",
    "    train_triplets = generator.generate_triplets(splits['train'])\n",
    "    val_triplets = generator.generate_triplets(splits['val'])\n",
    "    test_triplets = generator.generate_triplets(splits['test'])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TripletDataset(train_triplets)\n",
    "    val_dataset = TripletDataset(val_triplets)\n",
    "    test_dataset = TripletDataset(test_triplets)\n",
    "    \n",
    "    # Create dataloaders (4 workers for optimal IO)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
    "                            num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198bd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "for batch in train_loader:\n",
    "    anchors = batch['anchor']  # numpy array (H, W, 3)\n",
    "    positives = batch['positive']\n",
    "    negatives = batch['negative']\n",
    "    \n",
    "    # Convert to tensors and normalize in your training loop:\n",
    "    # anchors_tensor = torch.from_numpy(anchors).permute(0, 3, 1, 2).float() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10838f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9ed75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac08e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99a1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036f069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(100),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = TripletFaceDataset(root_dir=\"path/to/dataset\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SiameseResNet(embedding_dim=256)\n",
    "criterion = TripletLoss(margin=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in dataloader:\n",
    "        anchor, positive, negative = batch\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        anchor_emb = model(anchor)\n",
    "        positive_emb = model(positive)\n",
    "        negative_emb = model(negative)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82942de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742f799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
