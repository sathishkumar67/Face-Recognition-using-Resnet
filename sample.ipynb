{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ba0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n",
      "Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e795deb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Face-Recognition-using-Resnet'...\n",
      "remote: Enumerating objects: 18, done.\u001b[K\n",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 18 (delta 3), reused 12 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (18/18), 70.80 KiB | 17.70 MiB/s, done.\n",
      "Resolving deltas: 100% (3/3), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sathishkumar67/Face-Recognition-using-Resnet.git\n",
    "!mv /kaggle/working/Face-Recognition-using-Resnet/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56e1ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from siamese_resnet import unzip_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87696724",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_REPO_ID = \"pt-sk/Face_Recognition_Dataset\"\n",
    "DATASET_FILENAME_IN_REPO = \"Face Recognition Dataset.zip\"\n",
    "DATASET_REPO_TYPE = \"dataset\"\n",
    "LOCAL_DIR = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd2fe865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping: 100%|██████████| 5.20G/5.20G [00:36<00:00, 142MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped /kaggle/working/Face Recognition Dataset.zip to /kaggle/working\n",
      "Removed zip file: /kaggle/working/Face Recognition Dataset.zip\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset from Hugging Face Hub\n",
    "hf_hub_download(repo_id=DATASET_REPO_ID, filename=DATASET_FILENAME_IN_REPO, repo_type=DATASET_REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "\n",
    "# Unzip the dataset\n",
    "unzip_file(os.path.join(LOCAL_DIR, DATASET_FILENAME_IN_REPO), LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81fe13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet loss function\n",
    "# This function computes the triplet loss for a batch of anchor, positive, and negative samples.\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        # Compute pairwise distances\n",
    "        distance_positive = F.pairwise_distance(anchor, positive)\n",
    "        distance_negative = F.pairwise_distance(anchor, negative)\n",
    "        \n",
    "        # Calculate triplet loss\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c813e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseResNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=256):\n",
    "        super(SiameseResNet, self).__init__()\n",
    "        # Load pretrained ResNet18\n",
    "        self.backbone = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        self.backbone.fc = nn.Linear(512, embedding_dim)  # 512 -> 256\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def print_parameters_count(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters()) / 1e6  # Convert to millions\n",
    "        # Print the number of parameters in millions\n",
    "        print(f\"Total parameters: {total_params:.2f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e448056e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 11.31m\n"
     ]
    }
   ],
   "source": [
    "model = SiameseResNet(embedding_dim=256)\n",
    "model.print_parameters_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e49529ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass a sample image through the model\n",
    "dummy_input = torch.randn(1, 3, 224, 224)  # batch size of 1, 3 channels, 224x224 image\n",
    "output = model(dummy_input)\n",
    "output.shape  # should be (1, 256) since we changed the final layer to output 256 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deb0e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.id_to_images = defaultdict(list)\n",
    "        \n",
    "        # Populate identities and their images\n",
    "        for identity in os.listdir(root_dir):\n",
    "            identity_dir = os.path.join(root_dir, identity)\n",
    "            if os.path.isdir(identity_dir):\n",
    "                images = [os.path.join(identity_dir, img) \n",
    "                          for img in os.listdir(identity_dir) \n",
    "                          if img.endswith(('.jpg', '.png'))]\n",
    "                if len(images) >= 2:  # Ensure at least 2 images per identity\n",
    "                    self.id_to_images[identity] = images\n",
    "        self.identities = list(self.id_to_images.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.identities) * 10  # Adjust based on your needs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Anchor and positive from the same identity\n",
    "        anchor_id = self.identities[idx % len(self.identities)]\n",
    "        anchor_img_path, positive_img_path = random.sample(self.id_to_images[anchor_id], 2)\n",
    "        \n",
    "        # Negative from a different identity\n",
    "        negative_id = random.choice(self.identities)\n",
    "        while negative_id == anchor_id:\n",
    "            negative_id = random.choice(self.identities)\n",
    "        negative_img_path = random.choice(self.id_to_images[negative_id])\n",
    "        \n",
    "        # Load and transform images\n",
    "        anchor = Image.open(anchor_img_path).convert('RGB')\n",
    "        positive = Image.open(positive_img_path).convert('RGB')\n",
    "        negative = Image.open(negative_img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "        \n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65a2fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TripletFaceDataset(root_dir='Face Recognition Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a048f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, p, n = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(100),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = TripletFaceDataset(root_dir=\"path/to/dataset\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SiameseResNet(embedding_dim=256)\n",
    "criterion = TripletLoss(margin=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in dataloader:\n",
    "        anchor, positive, negative = batch\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        anchor_emb = model(anchor)\n",
    "        positive_emb = model(positive)\n",
    "        negative_emb = model(negative)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
