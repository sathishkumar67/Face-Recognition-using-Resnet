{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ba0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Face-Recognition-using-Resnet'...\n",
      "remote: Enumerating objects: 59, done.\u001b[K\n",
      "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
      "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
      "remote: Total 59 (delta 24), reused 42 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (59/59), 219.86 KiB | 9.99 MiB/s, done.\n",
      "Resolving deltas: 100% (24/24), done.\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.1.1\n",
      "Collecting tensorflow==2.19.0 (from -r requirements.txt (line 1))\n",
      "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mtcnn==1.0.0 (from -r requirements.txt (line 2))\n",
      "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
      "Requirement already satisfied: huggingface-hub==0.30.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.30.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (1.70.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (3.12.1)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow==2.19.0->-r requirements.txt (line 1))\n",
      "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 4)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 4)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 4)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 4)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 4)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn==1.0.0->-r requirements.txt (line 2)) (1.4.2)\n",
      "Collecting lz4>=4.3.3 (from mtcnn==1.0.0->-r requirements.txt (line 2))\n",
      "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 6)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 6)) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (14.0.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 4)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 4)) (2022.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 4)) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 4)) (2024.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lz4, mtcnn, ml-dtypes, tensorboard, tensorflow\n",
      "\u001b[2K  Attempting uninstall: ml-dtypes\n",
      "\u001b[2K    Found existing installation: ml-dtypes 0.4.1\n",
      "\u001b[2K    Uninstalling ml-dtypes-0.4.1:\n",
      "\u001b[2K      Successfully uninstalled ml-dtypes-0.4.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [ml-dtypes]\n",
      "\u001b[2K  Attempting uninstall: tensorboard[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [ml-dtypes]\n",
      "\u001b[2K    Found existing installation: tensorboard 2.18.0━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [ml-dtypes]\n",
      "\u001b[2K    Uninstalling tensorboard-2.18.0:90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [ml-dtypes]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.18.00m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [tensorboard]\n",
      "\u001b[2K  Attempting uninstall: tensorflow0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: tensorflow 2.18.0━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [tensorboard]\n",
      "\u001b[2K    Uninstalling tensorflow-2.18.0:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [tensorflow]\n",
      "\u001b[2K      Successfully uninstalled tensorflow-2.18.0m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [tensorflow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [tensorflow]5\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
      "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed lz4-4.4.4 ml-dtypes-0.5.1 mtcnn-1.0.0 tensorboard-2.19.0 tensorflow-2.19.0\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\n",
      "Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m156.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.937\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━\u001b[0m \u001b[32m0/7\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.90 [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.90:0m \u001b[32m0/7\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.90━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.83━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.83:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.4.1━━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.8.93[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75━━━━━━━━━\u001b[0m \u001b[32m5/7\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m5/7\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.3.90[0m \u001b[32m5/7\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.3.90:90m━━━━━━━━━━━\u001b[0m \u001b[32m5/7\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90━━━━━\u001b[0m \u001b[32m6/7\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [nvidia-cusolver-cu12]dia-cusolver-cu12]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sathishkumar67/Face-Recognition-using-Resnet.git\n",
    "!mv /kaggle/working/Face-Recognition-using-Resnet/* /kaggle/working/\n",
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e1ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from siamese_resnet.utils import unzip_file\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87696724",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_REPO_ID = \"pt-sk/Face_Recognition_Dataset\"\n",
    "DATA_ROOT = \"face_recognition_with_cropped_faces_dataset\"\n",
    "DATASET_FILENAME_IN_REPO = f\"{DATA_ROOT}.zip\"\n",
    "DATASET_REPO_TYPE = \"dataset\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd2fe865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796df2257dc34a2483b7c0964d1f8ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)cognition_with_cropped_faces_dataset.zip:   0%|          | 0.00/1.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping: 100%|██████████| 1.31G/1.31G [00:14<00:00, 90.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped /kaggle/working/face_recognition_with_cropped_faces_dataset.zip to /kaggle/working\n",
      "Removed zip file: /kaggle/working/face_recognition_with_cropped_faces_dataset.zip\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset from Hugging Face Hub\n",
    "hf_hub_download(repo_id=DATASET_REPO_ID, filename=DATASET_FILENAME_IN_REPO, repo_type=DATASET_REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "\n",
    "# Unzip the dataset\n",
    "unzip_file(os.path.join(LOCAL_DIR, DATASET_FILENAME_IN_REPO), LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a0021fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from siamese_resnet.dataset import TripletDataset, TripletDatasetGenerator\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Initialize generator\n",
    "generator = TripletDatasetGenerator(DATA_ROOT)\n",
    "\n",
    "# Create splits\n",
    "splits = generator.create_splits()\n",
    "    \n",
    "# Generate triplets for each split\n",
    "train_triplets = generator.generate_triplets(splits['train'])\n",
    "val_triplets = generator.generate_triplets(splits['val'])\n",
    "test_triplets = generator.generate_triplets(splits['test'])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TripletDataset(train_triplets)\n",
    "val_dataset = TripletDataset(val_triplets)\n",
    "test_dataset = TripletDataset(test_triplets)\n",
    "    \n",
    "    # Create dataloaders (4 workers for optimal IO)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
    "    #                         num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7df588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, collate_fn=triplet_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15ab6c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e43f1770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]),\n",
       " torch.Size([1, 3, 224, 224]),\n",
       " torch.Size([1, 3, 224, 224]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"anchor\"].shape, a[\"positive\"].shape, a[\"negative\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f28f35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(a[\"anchor\"].permute(0, 2, 3, 1)[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "653c4e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3725, 0.3608, 0.3373,  ..., 0.4784, 0.4941, 0.5020],\n",
       "          [0.3529, 0.3490, 0.3451,  ..., 0.4392, 0.4667, 0.4863],\n",
       "          [0.3569, 0.3569, 0.3529,  ..., 0.3961, 0.4235, 0.4392],\n",
       "          ...,\n",
       "          [0.6235, 0.5922, 0.5490,  ..., 0.2627, 0.2745, 0.2902],\n",
       "          [0.6314, 0.5961, 0.5490,  ..., 0.2627, 0.2824, 0.3020],\n",
       "          [0.6353, 0.6039, 0.5608,  ..., 0.2784, 0.3020, 0.3176]],\n",
       "\n",
       "         [[0.2235, 0.2118, 0.1765,  ..., 0.3333, 0.3412, 0.3490],\n",
       "          [0.2039, 0.2000, 0.1843,  ..., 0.2941, 0.3137, 0.3333],\n",
       "          [0.2078, 0.2078, 0.2039,  ..., 0.2588, 0.2784, 0.2941],\n",
       "          ...,\n",
       "          [0.4431, 0.4118, 0.3686,  ..., 0.0941, 0.1137, 0.1412],\n",
       "          [0.4431, 0.4078, 0.3647,  ..., 0.0941, 0.1333, 0.1608],\n",
       "          [0.4471, 0.4157, 0.3765,  ..., 0.1098, 0.1529, 0.1765]],\n",
       "\n",
       "         [[0.1412, 0.1294, 0.0980,  ..., 0.2627, 0.2745, 0.2824],\n",
       "          [0.1216, 0.1176, 0.1059,  ..., 0.2235, 0.2471, 0.2667],\n",
       "          [0.1333, 0.1333, 0.1294,  ..., 0.1843, 0.2078, 0.2235],\n",
       "          ...,\n",
       "          [0.3412, 0.3098, 0.2667,  ..., 0.0275, 0.0431, 0.0667],\n",
       "          [0.3529, 0.3176, 0.2627,  ..., 0.0196, 0.0510, 0.0745],\n",
       "          [0.3569, 0.3255, 0.2745,  ..., 0.0353, 0.0706, 0.0902]]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"anchor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed3cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d86d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8f98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet loss function\n",
    "# This function computes the triplet loss for a batch of anchor, positive, and negative samples.\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        # Compute pairwise distances\n",
    "        distance_positive = F.pairwise_distance(anchor, positive)\n",
    "        distance_negative = F.pairwise_distance(anchor, negative)\n",
    "        \n",
    "        # Calculate triplet loss\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseResNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=256):\n",
    "        super(SiameseResNet, self).__init__()\n",
    "        # Load pretrained ResNet18\n",
    "        self.backbone = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        self.backbone.fc = nn.Linear(512, embedding_dim)  # 512 -> 256\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def print_parameters_count(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters()) / 1e6  # Convert to millions\n",
    "        # Print the number of parameters in millions\n",
    "        print(f\"Total parameters: {total_params:.2f}m\")\n",
    "    \n",
    "model = SiameseResNet(embedding_dim=256)\n",
    "# model.print_parameters_count()\n",
    "\n",
    "# pass a sample image through the model\n",
    "dummy_input = torch.randn(1, 3, 224, 224)  # batch size of 1, 3 channels, 224x224 image\n",
    "output = model(dummy_input)\n",
    "# output.shape  # should be (1, 256) since we changed the final layer to output 256 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.id_to_images = defaultdict(list)\n",
    "        \n",
    "        # Populate identities and their images\n",
    "        for identity in os.listdir(root_dir):\n",
    "            identity_dir = os.path.join(root_dir, identity)\n",
    "            if os.path.isdir(identity_dir):\n",
    "                images = [os.path.join(identity_dir, img) \n",
    "                        for img in os.listdir(identity_dir) \n",
    "                        if img.endswith(('.jpg', '.png'))]\n",
    "                if len(images) >= 2:  # Ensure at least 2 images per identity\n",
    "                    self.id_to_images[identity] = images\n",
    "        self.identities = list(self.id_to_images.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.identities) * 10  # Adjust based on your needs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Anchor and positive from the same identity\n",
    "        anchor_id = self.identities[idx % len(self.identities)]\n",
    "        anchor_img_path, positive_img_path = random.sample(self.id_to_images[anchor_id], 2)\n",
    "        \n",
    "        # Negative from a different identity\n",
    "        negative_id = random.choice(self.identities)\n",
    "        while negative_id == anchor_id:\n",
    "            negative_id = random.choice(self.identities)\n",
    "        negative_img_path = random.choice(self.id_to_images[negative_id])\n",
    "        \n",
    "        # Load and transform images\n",
    "        anchor = Image.open(anchor_img_path).convert('RGB')\n",
    "        positive = Image.open(positive_img_path).convert('RGB')\n",
    "        negative = Image.open(negative_img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "        \n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a757a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletFaceDataset(root_dir='sample_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a01bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34d82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10838f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9ed75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac08e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99a1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036f069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(100),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = TripletFaceDataset(root_dir=\"path/to/dataset\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SiameseResNet(embedding_dim=256)\n",
    "criterion = TripletLoss(margin=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in dataloader:\n",
    "        anchor, positive, negative = batch\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        anchor_emb = model(anchor)\n",
    "        positive_emb = model(positive)\n",
    "        negative_emb = model(negative)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82942de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742f799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
